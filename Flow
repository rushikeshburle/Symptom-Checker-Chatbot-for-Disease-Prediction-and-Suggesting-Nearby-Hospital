## Flow of chat.py 

python app.py  >>>> run

1. Fetch current location using IP.
2. Load medical center data from JSON file.
3. Initialize an empty list to store distances.
4. For each medical center:
   a. Get the center's coordinates.
   b. Compute the distance to the current location using Haversine formula.
   c. Store the center's name, distance, and address in a list.
5. Sort the list of centers by distance.
6. Select the top 5 nearest centers.
7. Prepare the output as a list of [name, distance, address].
8. Return or display the result.



Step-by-Step Logic

Fetch Current Location:
The geocoder.ip('me') fetches your current geographical location based on your IP address.
The latitude and longitude are stored in given_location.

Load JSON Data:
Open the medical_centers.json file and parse its content. This file is expected to contain data about medical centers, including their name (tag), geographic coordinates (location), and address.

Calculate Distance for Each Center:
For each medical center in the JSON file, the script calculates the distance between your current location and the center's coordinates using the Haversine formula. This formula computes the great-circle distance between two points on a sphere given their latitudes and longitudes.

Store and Sort by Distance:
It stores the center's name (tag), calculated distance, and address in a list.
This list is then sorted in ascending order of distance.

Select Top 5 Closest Centers:
After sorting, the script selects the first five entries (i.e., the five closest centers).

Format the Output:
For each of the closest centers, it prepares a list containing the center's name, distance (rounded to two decimal places), and address.


The code provided is part of a Python chatbot that fetches and processes location-based data for medical centers. 
It includes:
Geo location: Determines the current location using the geocoder library.
JSON Parsing: Loads a JSON file containing medical center data.
Distance Calculation: Computes distances from the user's location to the centers using the Haversine formula.
Sorting and Output: Sorts the centers by proximity and extracts details of the closest five.

# **# Model.py Flow**

The RNNModel class defines a neural network using Long Short-Term Memory (LSTM), which is a type of Recurrent Neural Network (RNN). This model processes sequential data, such as time-series data or text, and outputs predictions based on the patterns learned from the input.


1. Class Initialization (__init__):
   
Parameters:
input_size: Number of features in each time step of the input data.
hidden_size: Number of units in the LSTM's hidden state (controls the capacity of the model).
output_size: The size of the final output (e.g., number of classes for classification).
num_layers: Number of LSTM layers stacked together.

Components:
self.lstm:
This is an LSTM layer that processes sequential input.
It takes input with dimensions [batch_size, sequence_length, input_size] and outputs a sequence of hidden states for each time step.
batch_first=True ensures the input and output tensors have the batch size as the first dimension.
self.fc:
A fully connected (linear) layer that maps the LSTM's hidden state output to the desired output size.


2. Forward Pass (forward):
The forward method defines how the model processes the input to produce an output:

The LSTM processes the input x and returns:
out: A tensor containing the hidden states for all time steps with shape [batch_size, sequence_length, hidden_size].
hn: The final hidden state of the LSTM for all layers (not used here).
cn: The final cell state of the LSTM for all layers (not used here).

Select the Last Time Step's Output:
out[:, -1, :]: Selects the hidden state of the last time step in the sequence for each batch. This represents the sequence's overall context.
self.fc: Passes this selected output through the fully connected layer to produce the final output with shape [batch_size, output_size].

The RNNModel performs the following:
Processes sequential data through an LSTM layer to learn patterns in the sequence.
Uses the final time stepâ€™s output to represent the sequence's information.
Maps this representation to the desired output size using a fully connected layer.


